"""
AIåˆ†ææ¨¡å—
è´Ÿè´£è°ƒç”¨AIæ¨¡å‹ï¼Œåˆ†ææ–‡ä»¶å¹¶ç»™å‡ºæ•´ç†å»ºè®®

æ”¯æŒå¤šç§AIæä¾›å•†ï¼š
- tongyi: é€šä¹‰åƒé—®
- rule_based: è§„åˆ™å¼•æ“ï¼ˆä¸ä¾èµ–AIï¼‰
- å¯æ‰©å±•ï¼šopenai, ollamaç­‰
"""
import json
from typing import List, Dict, Optional
import config
from core.ai_providers import AIProviderFactory, AIProvider
from core.user_config import get_config_manager


class AIAnalyzer:
    """AIæ–‡ä»¶åˆ†æå™¨ï¼ˆæ”¯æŒå¤šæä¾›å•†ï¼‰"""

    def __init__(self, provider_type: str = None):
        """
        åˆå§‹åŒ–AIåˆ†æå™¨
        :param provider_type: AIæä¾›å•†ç±»å‹ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨ç”¨æˆ·é…ç½®
        """
        # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®
        self.config_manager = get_config_manager()

        # å¦‚æœæ²¡æœ‰æŒ‡å®šprovider_typeï¼Œä»ç”¨æˆ·é…ç½®è¯»å–
        if provider_type is None:
            provider_type = self.config_manager.get('ai_provider', config.AI_PROVIDER)

        self.provider_type = provider_type
        self.fallback_enabled = self.config_manager.get('ai_fallback', config.AI_FALLBACK_TO_RULES)

        # åˆ›å»ºAIæä¾›å•†
        self.provider = self._create_provider(self.provider_type)

    def _create_provider(self, provider_type: str) -> AIProvider:
        """åˆ›å»ºAIæä¾›å•†"""
        # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨config.pyçš„é»˜è®¤å€¼
        provider_config = {
            'api_key': self.config_manager.get('tongyi_api_key', config.TONGYI_API_KEY),
            'model': self.config_manager.get('tongyi_model', config.TONGYI_MODEL),
            'timeout': self.config_manager.get('ai_timeout', config.AI_TIMEOUT),
            'max_retries': config.AI_MAX_RETRIES,
            'retry_delay': config.AI_RETRY_DELAY,
            'enable_detail_log': config.ENABLE_DETAIL_LOG,
            'old_file_days': self.config_manager.get('rule_old_file_days', config.RULE_OLD_FILE_DAYS),
            'temp_file_days': self.config_manager.get('rule_temp_file_days', config.RULE_TEMP_FILE_DAYS),
        }

        return AIProviderFactory.create_provider(provider_type, provider_config)

    def analyze_files(self, files: List[Dict], progress_callback=None) -> Dict:
        """
        åˆ†ææ–‡ä»¶åˆ—è¡¨ï¼Œè¿”å›æ•´ç†å»ºè®®ï¼ˆæ”¯æŒåˆ†æ‰¹å¤„ç†ï¼‰

        :param files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å« name, path, extension, size_kb, modified_time ç­‰å­—æ®µ
        :param progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (current_batch, total_batches, batch_result) å‚æ•°
        :return: åˆ†æç»“æœï¼ŒåŒ…å«åˆ†ç±»å»ºè®®ã€åˆ é™¤å»ºè®®ç­‰

        è¿”å›æ ¼å¼ç¤ºä¾‹:
        {
            'suggestions': [
                {
                    'file_path': '/path/to/file1.txt',
                    'action': 'delete',  # delete åˆ é™¤, move ç§»åŠ¨, keep ä¿ç•™
                    'reason': 'è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ï¼Œå·²è¶…è¿‡30å¤©æœªä½¿ç”¨',
                    'category': 'ä¸´æ—¶æ–‡ä»¶',
                    'confidence': 0.9  # ç½®ä¿¡åº¦ 0-1
                },
                ...
            ],
            'categories': {
                'ä¸´æ—¶æ–‡ä»¶': ['file1.txt', 'file2.txt'],
                'é‡è¦æ–‡æ¡£': ['file3.docx'],
                ...
            }
        }
        """

        # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
        batch_size = self.config_manager.get('max_files_per_request', config.MAX_FILES_PER_REQUEST)
        total_files = len(files)

        if total_files > batch_size:
            print(f"\n" + "="*80)
            print(f"ğŸ“¦ æ‰¹é‡å¤„ç†æ¨¡å¼")
            print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
            print(f"   æ¯æ‰¹å¤§å°: {batch_size} (å¯åœ¨config.pyä¸­è°ƒæ•´MAX_FILES_PER_REQUEST)")
            total_batches = (total_files + batch_size - 1) // batch_size
            print(f"   åˆ†æ‰¹æ•°é‡: {total_batches}")
            print("="*80)

            # åˆ†æ‰¹å¤„ç†å¹¶åˆå¹¶ç»“æœ
            all_suggestions = []
            all_categories = {}

            for i in range(0, total_files, batch_size):
                batch = files[i:i + batch_size]
                batch_num = i // batch_size + 1

                print(f"\n" + "â–¶"*40)
                print(f"ğŸ“‹ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}")
                print(f"   æ–‡ä»¶èŒƒå›´: {i+1} - {min(i+batch_size, total_files)}")
                print(f"   æœ¬æ‰¹æ–‡ä»¶æ•°: {len(batch)}")
                print(f"   æ–‡ä»¶åˆ—è¡¨:")
                for idx, f in enumerate(batch[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"      {idx}. {f['name']} ({f['size_kb']}KB)")
                if len(batch) > 5:
                    print(f"      ... è¿˜æœ‰ {len(batch)-5} ä¸ªæ–‡ä»¶")
                print("â–¶"*40 + "\n")

                batch_result = self._analyze_batch(batch, batch_num, total_batches)

                # ç»Ÿè®¡æœ¬æ‰¹ç»“æœ
                batch_suggestions_count = len(batch_result.get('suggestions', []))
                print(f"\nâœ”ï¸  æ‰¹æ¬¡ {batch_num} å®Œæˆï¼Œè·å¾— {batch_suggestions_count} æ¡å»ºè®®\n")

                all_suggestions.extend(batch_result.get('suggestions', []))

                # åˆå¹¶åˆ†ç±»
                for category, file_list in batch_result.get('categories', {}).items():
                    if category in all_categories:
                        all_categories[category].extend(file_list)
                    else:
                        all_categories[category] = file_list

                # è°ƒç”¨è¿›åº¦å›è°ƒï¼Œå®æ—¶æ›´æ–°GUI
                if progress_callback:
                    progress_callback(batch_num, total_batches, batch_result)

            print(f"\n" + "="*80)
            print(f"ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼")
            print(f"   æ€»å»ºè®®æ•°: {len(all_suggestions)}")
            print(f"   åˆ†ç±»æ•°: {len(all_categories)}")
            print("="*80 + "\n")

            return {
                'suggestions': all_suggestions,
                'categories': all_categories
            }
        else:
            # æ–‡ä»¶æ•°é‡ä¸å¤šï¼Œç›´æ¥å¤„ç†
            print(f"\nğŸ“‹ å•æ‰¹å¤„ç†æ¨¡å¼ - å…± {total_files} ä¸ªæ–‡ä»¶\n")
            result = self._analyze_batch(files, 1, 1)

            # è°ƒç”¨è¿›åº¦å›è°ƒ
            if progress_callback:
                progress_callback(1, 1, result)

            return result

    def _analyze_batch(self, files: List[Dict], batch_num: int = 1, total_batches: int = 1) -> Dict:
        """
        åˆ†æä¸€æ‰¹æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        :param files: æ–‡ä»¶åˆ—è¡¨
        :param batch_num: å½“å‰æ‰¹æ¬¡å·
        :param total_batches: æ€»æ‰¹æ¬¡æ•°
        """
        print(f"ğŸ”„ å¼€å§‹åˆ†ææ‰¹æ¬¡ {batch_num}/{total_batches}...")

        # è°ƒç”¨AIæä¾›å•†
        try:
            result = self.provider.analyze_files(files)

            # è§£ææˆåŠŸæ—¥å¿—
            suggestions_count = len(result.get('suggestions', []))
            print(f"âœ… æ‰¹æ¬¡ {batch_num} è§£ææˆåŠŸï¼Œè·å¾— {suggestions_count} æ¡å»ºè®®")

            return result

        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_num} AIåˆ†æå¤±è´¥: {e}")

            # å¦‚æœå¯ç”¨äº†fallbackä¸”ä¸æ˜¯è§„åˆ™å¼•æ“
            if self.fallback_enabled and self.provider_type != 'rule_based':
                print(f"\nâš ï¸  æ­£åœ¨åˆ‡æ¢åˆ°è§„åˆ™å¼•æ“ä½œä¸ºfallback...")
                try:
                    fallback_provider = self._create_provider('rule_based')
                    result = fallback_provider.analyze_files(files)
                    print(f"âœ… è§„åˆ™å¼•æ“fallbackæˆåŠŸ")
                    return result
                except Exception as fallback_error:
                    print(f"âŒ è§„åˆ™å¼•æ“fallbackä¹Ÿå¤±è´¥: {fallback_error}")

            return self._get_empty_result()

    def _get_empty_result(self) -> Dict:
        """è¿”å›ç©ºç»“æœ"""
        return {
            'suggestions': [],
            'categories': {}
        }


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("="*80)
    print("AIåˆ†æå™¨æµ‹è¯•")
    print("="*80)

    # æ¨¡æ‹Ÿæ–‡ä»¶åˆ—è¡¨
    test_files = [
        {
            'name': 'temp_file.tmp',
            'path': '/home/user/Desktop/temp_file.tmp',
            'extension': '.tmp',
            'size_kb': 1536.0,
            'size_mb': 1.5,
            'modified_time': '2024-01-15 10:30:00'
        },
        {
            'name': 'important_doc.pdf',
            'path': '/home/user/Desktop/important_doc.pdf',
            'extension': '.pdf',
            'size_kb': 5324.8,
            'size_mb': 5.2,
            'modified_time': '2025-11-10 14:20:00'
        },
        {
            'name': 'photo.jpg',
            'path': '/home/user/Desktop/photo.jpg',
            'extension': '.jpg',
            'size_kb': 2048.0,
            'size_mb': 2.0,
            'modified_time': '2025-10-01 12:00:00'
        }
    ]

    # æµ‹è¯•ä¸åŒçš„æä¾›å•†
    print("\næµ‹è¯•1: ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æä¾›å•†")
    analyzer1 = AIAnalyzer()
    result1 = analyzer1.analyze_files(test_files)
    print("åˆ†æç»“æœ:")
    print(json.dumps(result1, indent=2, ensure_ascii=False))

    print("\n" + "="*80)
    print("æµ‹è¯•2: å¼ºåˆ¶ä½¿ç”¨è§„åˆ™å¼•æ“")
    analyzer2 = AIAnalyzer(provider_type='rule_based')
    result2 = analyzer2.analyze_files(test_files)
    print("åˆ†æç»“æœ:")
    print(json.dumps(result2, indent=2, ensure_ascii=False))

    print("\n" + "="*80)
    print("æµ‹è¯•å®Œæˆï¼")
