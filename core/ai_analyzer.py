"""
AIåˆ†ææ¨¡å—
è´Ÿè´£è°ƒç”¨é€šä¹‰å¤§æ¨¡å‹ï¼Œåˆ†ææ–‡ä»¶å¹¶ç»™å‡ºæ•´ç†å»ºè®®

ã€é‡è¦ã€‘è¯·åœ¨æ­¤æ–‡ä»¶ä¸­å¡«å†™é€šä¹‰å¤§æ¨¡å‹çš„è°ƒç”¨ä»£ç 
"""
import json
from typing import List, Dict, Optional
import config

# TODO: å¯¼å…¥é€šä¹‰åƒé—®çš„SDK
# ç¤ºä¾‹: from dashscope import Generation
# æˆ–è€…ä½¿ç”¨ OpenAI å…¼å®¹çš„ API


class AIAnalyzer:
    """AIæ–‡ä»¶åˆ†æå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–AIåˆ†æå™¨"""
        self.api_key = config.TONGYI_API_KEY
        self.model = config.TONGYI_MODEL

        # TODO: åˆå§‹åŒ–é€šä¹‰åƒé—®å®¢æˆ·ç«¯
        # ç¤ºä¾‹:
        # import dashscope
        # dashscope.api_key = self.api_key

    def analyze_files(self, files: List[Dict]) -> Dict:
        """
        åˆ†ææ–‡ä»¶åˆ—è¡¨ï¼Œè¿”å›æ•´ç†å»ºè®®ï¼ˆæ”¯æŒåˆ†æ‰¹å¤„ç†ï¼‰

        :param files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å« name, path, extension, size_mb, modified_time ç­‰å­—æ®µ
        :return: åˆ†æç»“æœï¼ŒåŒ…å«åˆ†ç±»å»ºè®®ã€åˆ é™¤å»ºè®®ç­‰

        è¿”å›æ ¼å¼ç¤ºä¾‹:
        {
            'suggestions': [
                {
                    'file_path': '/path/to/file1.txt',
                    'action': 'delete',  # delete åˆ é™¤, move ç§»åŠ¨, keep ä¿ç•™
                    'reason': 'è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ï¼Œå·²è¶…è¿‡30å¤©æœªä½¿ç”¨',
                    'category': 'ä¸´æ—¶æ–‡ä»¶',
                    'confidence': 0.9  # ç½®ä¿¡åº¦ 0-1
                },
                ...
            ],
            'categories': {
                'ä¸´æ—¶æ–‡ä»¶': ['file1.txt', 'file2.txt'],
                'é‡è¦æ–‡æ¡£': ['file3.docx'],
                ...
            }
        }
        """

        # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
        batch_size = config.MAX_FILES_PER_REQUEST
        total_files = len(files)

        if total_files > batch_size:
            print(f"æ–‡ä»¶æ•°é‡ {total_files} è¶…è¿‡é™åˆ¶ {batch_size}ï¼Œå°†åˆ†æ‰¹å¤„ç†...")

            # åˆ†æ‰¹å¤„ç†å¹¶åˆå¹¶ç»“æœ
            all_suggestions = []
            all_categories = {}

            for i in range(0, total_files, batch_size):
                batch = files[i:i + batch_size]
                batch_num = i // batch_size + 1
                total_batches = (total_files + batch_size - 1) // batch_size
                print(f"å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼Œ{len(batch)} ä¸ªæ–‡ä»¶...")

                batch_result = self._analyze_batch(batch)
                all_suggestions.extend(batch_result.get('suggestions', []))

                # åˆå¹¶åˆ†ç±»
                for category, file_list in batch_result.get('categories', {}).items():
                    if category in all_categories:
                        all_categories[category].extend(file_list)
                    else:
                        all_categories[category] = file_list

            return {
                'suggestions': all_suggestions,
                'categories': all_categories
            }
        else:
            # æ–‡ä»¶æ•°é‡ä¸å¤šï¼Œç›´æ¥å¤„ç†
            return self._analyze_batch(files)

    def _analyze_batch(self, files: List[Dict]) -> Dict:
        """
        åˆ†æä¸€æ‰¹æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        """
        # æ„é€ å‘é€ç»™AIçš„æç¤ºè¯
        prompt = self._build_prompt(files)

        # è°ƒç”¨é€šä¹‰å¤§æ¨¡å‹API
        try:
            response_text = self._call_tongyi_api(prompt)
            result = self._parse_response(response_text)
            return result
        except Exception as e:
            print(f"AIåˆ†æå¤±è´¥: {e}")
            return self._get_empty_result()

    def _build_prompt(self, files: List[Dict]) -> str:
        """
        æ„å»ºå‘é€ç»™AIçš„æç¤ºè¯
        """
        # é™åˆ¶æ–‡ä»¶æ•°é‡ï¼Œé¿å…è¶…è¿‡tokené™åˆ¶
        if len(files) > config.MAX_FILES_PER_REQUEST:
            files = files[:config.MAX_FILES_PER_REQUEST]

        # æ„é€ æ–‡ä»¶åˆ—è¡¨çš„æè¿°
        files_description = "æ–‡ä»¶åˆ—è¡¨:\n"
        for i, file in enumerate(files, 1):
            files_description += f"{i}. {file['name']} - {file['size_mb']}MB - ä¿®æ”¹æ—¶é—´:{file['modified_time']}\n"
            files_description += f"   è·¯å¾„: {file['path']}\n"

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡ä»¶ç®¡ç†åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹æ¡Œé¢å’Œä¸‹è½½æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼Œå¹¶ç»™å‡ºæ•´ç†å»ºè®®ã€‚

{files_description}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š

{{
    "suggestions": [
        {{
            "file_path": "æ–‡ä»¶å®Œæ•´è·¯å¾„",
            "action": "delete/move/keep",
            "reason": "å»ºè®®ç†ç”±",
            "category": "æ–‡ä»¶åˆ†ç±»ï¼ˆå¦‚ï¼šä¸´æ—¶æ–‡ä»¶ã€é‡è¦æ–‡æ¡£ã€å›¾ç‰‡ç­‰ï¼‰",
            "confidence": 0.9
        }}
    ],
    "categories": {{
        "ä¸´æ—¶æ–‡ä»¶": ["æ–‡ä»¶å1", "æ–‡ä»¶å2"],
        "é‡è¦æ–‡æ¡£": ["æ–‡ä»¶å3"]
    }}
}}

åˆ†æè¦ç‚¹ï¼š
1. è¯†åˆ«ä¸´æ—¶æ–‡ä»¶ã€é‡å¤æ–‡ä»¶ã€è¿‡æœŸæ–‡ä»¶ï¼Œå»ºè®®åˆ é™¤
2. å°†æ–‡ä»¶æŒ‰ç±»å‹åˆ†ç±»ï¼ˆæ–‡æ¡£ã€å›¾ç‰‡ã€è§†é¢‘ã€å®‰è£…åŒ…ç­‰ï¼‰
3. æ ‡æ³¨æ¯ä¸ªå»ºè®®çš„ç½®ä¿¡åº¦
4. ç»™å‡ºæ¸…æ™°çš„ç†ç”±

ç°åœ¨è¯·å¼€å§‹åˆ†æã€‚"""

        return prompt

    def _call_tongyi_api(self, prompt: str) -> str:
        """
        è°ƒç”¨é€šä¹‰åƒé—®API

        ã€æ ¸å¿ƒæ–¹æ³• - è¯·åœ¨è¿™é‡Œå®ç°é€šä¹‰å¤§æ¨¡å‹çš„è°ƒç”¨ã€‘

        :param prompt: å‘é€ç»™AIçš„æç¤ºè¯
        :return: AIçš„å“åº”æ–‡æœ¬
        """

        # TODO: åœ¨è¿™é‡Œå®ç°é€šä¹‰åƒé—®APIè°ƒç”¨
        # ====================================
        # æ–¹æ³•1: ä½¿ç”¨ dashscope SDK
        # ====================================
        # import dashscope
        # from dashscope import Generation

        # # è®¾ç½®API Keyï¼ˆé‡è¦ï¼ï¼‰
        # dashscope.api_key = self.api_key

        # response = Generation.call(
        #     model=self.model,
        #     prompt=prompt,
        #     result_format='message'  # æˆ– 'text'
        # )
        
        # if response.status_code == 200:
        #     return response.output.text
        # else:
        #     raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.message}")

        # ====================================
        # æ–¹æ³•2: ä½¿ç”¨ OpenAI å…¼å®¹çš„ HTTP è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        # ====================================
        import requests
        import time

        url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }

        # é‡è¯•æœºåˆ¶ï¼šæœ€å¤šé‡è¯•3æ¬¡
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"\n{'='*60}")
                print(f"ğŸ“¡ æ­£åœ¨è°ƒç”¨é€šä¹‰åƒé—®APIï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰")
                print(f"ğŸ¤– æ¨¡å‹: {self.model}")
                print(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
                print(f"{'='*60}")

                response = requests.post(url, headers=headers, json=data, timeout=config.AI_TIMEOUT)
                response.raise_for_status()  # æ£€æŸ¥HTTPé”™è¯¯

                result = response.json()
                response_content = result['choices'][0]['message']['content']

                print(f"\nâœ… APIè°ƒç”¨æˆåŠŸï¼")
                print(f"ğŸ“Š å“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
                print(f"{'='*60}\n")

                return response_content

            except requests.exceptions.Timeout as e:
                print(f"è¯·æ±‚è¶…æ—¶ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    wait_time = 5 * (attempt + 1)  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise Exception(f"APIè°ƒç”¨è¶…æ—¶ï¼Œå·²é‡è¯•{max_retries}æ¬¡")

            except requests.exceptions.RequestException as e:
                print(f"ç½‘ç»œè¯·æ±‚é”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt < max_retries - 1:
                    wait_time = 3 * (attempt + 1)
                    print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {e}")

            except (KeyError, ValueError) as e:
                print(f"å“åº”è§£æé”™è¯¯: {e}")
                raise Exception(f"APIå“åº”æ ¼å¼é”™è¯¯: {e}")

        # ====================================
        # ä¸´æ—¶è¿”å›ï¼ˆç”¨äºæµ‹è¯•ï¼Œè¯·æ›¿æ¢ä¸ºå®é™…çš„APIè°ƒç”¨ï¼‰
        # ====================================
        # print("è­¦å‘Š: AI APIæœªé…ç½®ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®")
        # return self._get_mock_response()

    def _get_mock_response(self) -> str:
        """
        è·å–æ¨¡æ‹Ÿå“åº”ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
        å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™ä¸ªæ–¹æ³•ä¸ä¼šè¢«è°ƒç”¨
        """
        mock_result = {
            "suggestions": [
                {
                    "file_path": "/path/to/example.tmp",
                    "action": "delete",
                    "reason": "è¿™æ˜¯ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶",
                    "category": "ä¸´æ—¶æ–‡ä»¶",
                    "confidence": 0.85
                }
            ],
            "categories": {
                "ä¸´æ—¶æ–‡ä»¶": ["example.tmp"],
                "æ–‡æ¡£": [],
                "å›¾ç‰‡": []
            }
        }
        return json.dumps(mock_result, ensure_ascii=False)

    def _parse_response(self, response_text: str) -> Dict:
        """
        è§£æAIè¿”å›çš„JSONå“åº”
        """
        # å»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
        response_text = response_text.strip()
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.startswith('```'):
            response_text = response_text[3:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]

        response_text = response_text.strip()

        # è§£æJSON
        result = json.loads(response_text)

        # éªŒè¯æ ¼å¼
        if 'suggestions' not in result:
            result['suggestions'] = []
        if 'categories' not in result:
            result['categories'] = {}

        return result

    def _get_empty_result(self) -> Dict:
        """è¿”å›ç©ºç»“æœ"""
        return {
            'suggestions': [],
            'categories': {}
        }


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    analyzer = AIAnalyzer()

    # æ¨¡æ‹Ÿæ–‡ä»¶åˆ—è¡¨
    test_files = [
        {
            'name': 'temp_file.tmp',
            'path': '/home/user/Desktop/temp_file.tmp',
            'extension': '.tmp',
            'size_mb': 1.5,
            'modified_time': '2024-01-15 10:30:00'
        },
        {
            'name': 'important_doc.pdf',
            'path': '/home/user/Desktop/important_doc.pdf',
            'extension': '.pdf',
            'size_mb': 5.2,
            'modified_time': '2025-11-10 14:20:00'
        }
    ]

    result = analyzer.analyze_files(test_files)
    print("AIåˆ†æç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
